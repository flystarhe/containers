{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4e11a6f",
   "metadata": {},
   "source": [
    "# Get Started\n",
    "\n",
    "以下命令将启动一个特定版本的容器，同时把主机当前目录映射到容器`/workspace`目录\n",
    "```sh\n",
    "t=flystarhe/mmdet:v2.24.1 && \\\n",
    "docker run --gpus all -d -p 7000:9000 --ipc=host --name test -v \"$(pwd)\":/workspace ${t} notebook\n",
    "```\n",
    "\n",
    "这时你有两种方式来开始训练或验证任务：\n",
    "\n",
    "- Jupyter - http://hostname:7000/?token=hi\n",
    "- Bash - `docker exec -it test bash`\n",
    "\n",
    "本教程只针对Jupyter方式。目标为提高工作的效率和规范性，实现所有参与者聚焦[Perception Ecosystem](#)第二节的模式快速开展工作，而不是每位同时都需要重复的去和环境作斗争。\n",
    "\n",
    "## Prepare Config\n",
    "如果你想导出一份版本库里原始的\n",
    "```python\n",
    "from mmcv import Config\n",
    "\n",
    "MMDET_HOME = \"/opt/src/mmdetection\"\n",
    "CONFIG_FILE = \"configs/centernet/centernet_resnet18_140e_coco.py\"\n",
    "cfg = Config.fromfile(f\"{MMDET_HOME}/{CONFIG_FILE}\")\n",
    "cfg.dump(f\"/workspace/centernet_resnet18.py\")\n",
    "print(f\"Config:\\n{cfg.pretty_text}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991450d9",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd742f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1724\n",
      "drwxr-xr-x 2 root root    4096 May 31 14:45 .ipynb_checkpoints/\n",
      "-rw-r--r-- 1 root root    8437 Jun  1 08:42 centernet_resnet18.py\n",
      "drwxr-xr-x 4 root root    4096 May 17 21:19 coco2017_cat_dog/\n",
      "-rw-r--r-- 1 root root 1669120 May 31 08:56 coco2017_cat_dog.tar\n",
      "-rw-r--r-- 1 root root   65857 Jun  2 08:53 get_started.ipynb\n",
      "drwxr-xr-x 4 root root    4096 May 31 18:35 tmp/\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "rm -rf coco2017_cat_dog*\n",
    "wget -q https://github.com/flystarhe/containers/releases/download/v0.2.0/coco2017_cat_dog.tar\n",
    "tar -xf coco2017_cat_dog.tar\n",
    "ls -Alp ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3213ecad",
   "metadata": {},
   "source": [
    "```log\n",
    "coco2017_cat_dog\n",
    "├── train\n",
    "│   ├── data\n",
    "│   │   ├── 000000001319.jpg\n",
    "│   │   ├── 000000011635.jpg\n",
    "│   │   ├── 000000012764.jpg\n",
    "│   │   ├── 000000013636.jpg\n",
    "│   │   ├── 000000016759.jpg\n",
    "│   │   └── 000000018155.jpg\n",
    "│   └── labels.json\n",
    "└── validation\n",
    "    ├── data\n",
    "    │   ├── 000000022892.jpg\n",
    "    │   ├── 000000071226.jpg\n",
    "    │   ├── 000000169076.jpg\n",
    "    │   ├── 000000179392.jpg\n",
    "    │   ├── 000000189806.jpg\n",
    "    │   └── 000000219578.jpg\n",
    "    └── labels.json\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509d36e9",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "### Training on a single GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3eed8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARGS=\"/opt/src/mmdetection/configs/centernet/centernet_resnet18_140e_coco.py --work-dir /workspace/tmp/runs/coco2017_cat_dog_centernet_resnet18 --seed 41 --launcher none --cfg-options 'model.bbox_head.num_classes=2' 'data.samples_per_gpu=2' 'data.workers_per_gpu=2' 'data.train.dataset.classes=cat,dog' 'data.train.dataset.ann_file=/workspace/coco2017_cat_dog/train/labels.json' 'data.train.dataset.img_prefix=/workspace/coco2017_cat_dog/train/data/' 'data.val.classes=cat,dog' 'data.val.ann_file=/workspace/coco2017_cat_dog/validation/labels.json' 'data.val.img_prefix=/workspace/coco2017_cat_dog/validation/data/' 'data.test.classes=cat,dog' 'data.test.ann_file=/workspace/coco2017_cat_dog/validation/labels.json' 'data.test.img_prefix=/workspace/coco2017_cat_dog/validation/data/' 'log_config.interval=8' 'runner.max_epochs=3'\"\n",
      "/opt/src/mmdetection/mmdet/utils/setup_env.py:38: UserWarning: Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\n",
      "  warnings.warn(\n",
      "/opt/src/mmdetection/mmdet/utils/setup_env.py:48: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\n",
      "  warnings.warn(\n",
      "2022-06-02 08:54:07,989 - mmdet - INFO - Environment info:\n",
      "------------------------------------------------------------\n",
      "sys.platform: linux\n",
      "Python: 3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]\n",
      "CUDA available: True\n",
      "GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU\n",
      "CUDA_HOME: /usr/local/cuda\n",
      "NVCC: Cuda compilation tools, release 11.3, V11.3.109\n",
      "GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
      "PyTorch: 1.11.0\n",
      "PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.3\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 8.2\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "TorchVision: 0.12.0\n",
      "OpenCV: 4.5.5\n",
      "MMCV: 1.5.2\n",
      "MMCV Compiler: GCC 7.3\n",
      "MMCV CUDA Compiler: 11.3\n",
      "MMDetection: 2.24.1+73b4e65\n",
      "------------------------------------------------------------\n",
      "\n",
      "2022-06-02 08:54:08,265 - mmdet - INFO - Distributed training: False\n",
      "2022-06-02 08:54:08,532 - mmdet - INFO - Config:\n",
      "dataset_type = 'CocoDataset'\n",
      "data_root = 'data/coco/'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile', to_float32=True, color_type='color'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        type='PhotoMetricDistortion',\n",
      "        brightness_delta=32,\n",
      "        contrast_range=(0.5, 1.5),\n",
      "        saturation_range=(0.5, 1.5),\n",
      "        hue_delta=18),\n",
      "    dict(\n",
      "        type='RandomCenterCropPad',\n",
      "        crop_size=(512, 512),\n",
      "        ratios=(0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3),\n",
      "        mean=[0, 0, 0],\n",
      "        std=[1, 1, 1],\n",
      "        to_rgb=True,\n",
      "        test_pad_mode=None),\n",
      "    dict(type='Resize', img_scale=(512, 512), keep_ratio=True),\n",
      "    dict(type='RandomFlip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile', to_float32=True),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        scale_factor=1.0,\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(\n",
      "                type='RandomCenterCropPad',\n",
      "                ratios=None,\n",
      "                border=None,\n",
      "                mean=[0, 0, 0],\n",
      "                std=[1, 1, 1],\n",
      "                to_rgb=True,\n",
      "                test_mode=True,\n",
      "                test_pad_mode=['logical_or', 31],\n",
      "                test_pad_add_pix=1),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(\n",
      "                type='Collect',\n",
      "                meta_keys=('filename', 'ori_filename', 'ori_shape',\n",
      "                           'img_shape', 'pad_shape', 'scale_factor', 'flip',\n",
      "                           'flip_direction', 'img_norm_cfg', 'border'),\n",
      "                keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=2,\n",
      "    workers_per_gpu=2,\n",
      "    train=dict(\n",
      "        type='RepeatDataset',\n",
      "        times=5,\n",
      "        dataset=dict(\n",
      "            type='CocoDataset',\n",
      "            ann_file='/workspace/coco2017_cat_dog/train/labels.json',\n",
      "            img_prefix='/workspace/coco2017_cat_dog/train/data/',\n",
      "            pipeline=[\n",
      "                dict(\n",
      "                    type='LoadImageFromFile',\n",
      "                    to_float32=True,\n",
      "                    color_type='color'),\n",
      "                dict(type='LoadAnnotations', with_bbox=True),\n",
      "                dict(\n",
      "                    type='PhotoMetricDistortion',\n",
      "                    brightness_delta=32,\n",
      "                    contrast_range=(0.5, 1.5),\n",
      "                    saturation_range=(0.5, 1.5),\n",
      "                    hue_delta=18),\n",
      "                dict(\n",
      "                    type='RandomCenterCropPad',\n",
      "                    crop_size=(512, 512),\n",
      "                    ratios=(0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3),\n",
      "                    mean=[0, 0, 0],\n",
      "                    std=[1, 1, 1],\n",
      "                    to_rgb=True,\n",
      "                    test_pad_mode=None),\n",
      "                dict(type='Resize', img_scale=(512, 512), keep_ratio=True),\n",
      "                dict(type='RandomFlip', flip_ratio=0.5),\n",
      "                dict(\n",
      "                    type='Normalize',\n",
      "                    mean=[123.675, 116.28, 103.53],\n",
      "                    std=[58.395, 57.12, 57.375],\n",
      "                    to_rgb=True),\n",
      "                dict(type='DefaultFormatBundle'),\n",
      "                dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "            ],\n",
      "            classes=['cat', 'dog'])),\n",
      "    val=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='/workspace/coco2017_cat_dog/validation/labels.json',\n",
      "        img_prefix='/workspace/coco2017_cat_dog/validation/data/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile', to_float32=True),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                scale_factor=1.0,\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(\n",
      "                        type='RandomCenterCropPad',\n",
      "                        ratios=None,\n",
      "                        border=None,\n",
      "                        mean=[0, 0, 0],\n",
      "                        std=[1, 1, 1],\n",
      "                        to_rgb=True,\n",
      "                        test_mode=True,\n",
      "                        test_pad_mode=['logical_or', 31],\n",
      "                        test_pad_add_pix=1),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='DefaultFormatBundle'),\n",
      "                    dict(\n",
      "                        type='Collect',\n",
      "                        meta_keys=('filename', 'ori_filename', 'ori_shape',\n",
      "                                   'img_shape', 'pad_shape', 'scale_factor',\n",
      "                                   'flip', 'flip_direction', 'img_norm_cfg',\n",
      "                                   'border'),\n",
      "                        keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        classes=['cat', 'dog']),\n",
      "    test=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='/workspace/coco2017_cat_dog/validation/labels.json',\n",
      "        img_prefix='/workspace/coco2017_cat_dog/validation/data/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile', to_float32=True),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                scale_factor=1.0,\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(\n",
      "                        type='RandomCenterCropPad',\n",
      "                        ratios=None,\n",
      "                        border=None,\n",
      "                        mean=[0, 0, 0],\n",
      "                        std=[1, 1, 1],\n",
      "                        to_rgb=True,\n",
      "                        test_mode=True,\n",
      "                        test_pad_mode=['logical_or', 31],\n",
      "                        test_pad_add_pix=1),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='DefaultFormatBundle'),\n",
      "                    dict(\n",
      "                        type='Collect',\n",
      "                        meta_keys=('filename', 'ori_filename', 'ori_shape',\n",
      "                                   'img_shape', 'pad_shape', 'scale_factor',\n",
      "                                   'flip', 'flip_direction', 'img_norm_cfg',\n",
      "                                   'border'),\n",
      "                        keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        classes=['cat', 'dog']))\n",
      "evaluation = dict(interval=1, metric='bbox')\n",
      "optimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=1000,\n",
      "    warmup_ratio=0.001,\n",
      "    step=[18, 24])\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=3)\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=8, hooks=[dict(type='TextLoggerHook')])\n",
      "custom_hooks = [dict(type='NumClassCheckHook')]\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "opencv_num_threads = 0\n",
      "mp_start_method = 'fork'\n",
      "auto_scale_lr = dict(enable=False, base_batch_size=128)\n",
      "model = dict(\n",
      "    type='CenterNet',\n",
      "    backbone=dict(\n",
      "        type='ResNet',\n",
      "        depth=18,\n",
      "        norm_eval=False,\n",
      "        norm_cfg=dict(type='BN'),\n",
      "        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet18')),\n",
      "    neck=dict(\n",
      "        type='CTResNetNeck',\n",
      "        in_channel=512,\n",
      "        num_deconv_filters=(256, 128, 64),\n",
      "        num_deconv_kernels=(4, 4, 4),\n",
      "        use_dcn=False),\n",
      "    bbox_head=dict(\n",
      "        type='CenterNetHead',\n",
      "        num_classes=2,\n",
      "        in_channel=64,\n",
      "        feat_channel=64,\n",
      "        loss_center_heatmap=dict(type='GaussianFocalLoss', loss_weight=1.0),\n",
      "        loss_wh=dict(type='L1Loss', loss_weight=0.1),\n",
      "        loss_offset=dict(type='L1Loss', loss_weight=1.0)),\n",
      "    train_cfg=None,\n",
      "    test_cfg=dict(topk=100, local_maximum_kernel=3, max_per_img=100))\n",
      "work_dir = '/workspace/tmp/runs/coco2017_cat_dog_centernet_resnet18'\n",
      "auto_resume = False\n",
      "gpu_ids = [0]\n",
      "\n",
      "2022-06-02 08:54:08,532 - mmdet - INFO - Set random seed to 41, deterministic: False\n",
      "2022-06-02 08:54:08,616 - mmdet - INFO - initialize ResNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'torchvision://resnet18'}\n",
      "2022-06-02 08:54:08,616 - mmcv - INFO - load model from: torchvision://resnet18\n",
      "2022-06-02 08:54:08,616 - mmcv - INFO - load checkpoint from torchvision path: torchvision://resnet18\n",
      "2022-06-02 08:54:08,649 - mmcv - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: fc.weight, fc.bias\n",
      "\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "2022-06-02 08:54:11,074 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "2022-06-02 08:54:11,076 - mmdet - INFO - Start running, host: root@48fe24f1f65c, work_dir: /workspace/tmp/runs/coco2017_cat_dog_centernet_resnet18\n",
      "2022-06-02 08:54:11,077 - mmdet - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2022-06-02 08:54:11,077 - mmdet - INFO - workflow: [('train', 1)], max: 3 epochs\n",
      "2022-06-02 08:54:11,077 - mmdet - INFO - Checkpoints will be saved to /workspace/tmp/runs/coco2017_cat_dog_centernet_resnet18 by HardDiskBackend.\n",
      "2022-06-02 08:54:14,275 - mmdet - INFO - Epoch [1][8/16]\tlr: 1.599e-04, eta: 0:00:15, time: 0.400, data_time: 0.266, memory: 478, loss_center_heatmap: 27.4696, loss_wh: 7.1921, loss_offset: 0.5085, loss: 35.1701, grad_norm: 183.9600\n",
      "2022-06-02 08:54:14,644 - mmdet - INFO - Exp name: centernet_resnet18_140e_coco.py\n",
      "2022-06-02 08:54:14,644 - mmdet - INFO - Epoch [1][16/16]\tlr: 3.197e-04, eta: 0:00:07, time: 0.046, data_time: 0.004, memory: 478, loss_center_heatmap: 10.3306, loss_wh: 7.6641, loss_offset: 0.4835, loss: 18.4782, grad_norm: 70.0089\n",
      "2022-06-02 08:54:14,662 - mmdet - INFO - Saving checkpoint at 1 epochs\n",
      "[                                                  ] 0/6, elapsed: 0s, ETA:/opt/src/mmdetection/mmdet/models/utils/gaussian_target.py:227: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  topk_clses = topk_inds // (height * width)\n",
      "/opt/src/mmdetection/mmdet/models/utils/gaussian_target.py:229: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  topk_ys = topk_inds // width\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 6/6, 38.6 task/s, elapsed: 0s, ETA:     0s2022-06-02 08:54:15,027 - mmdet - INFO - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.02s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      "2022-06-02 08:54:15,058 - mmdet - INFO - \n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.000\n",
      "\n",
      "2022-06-02 08:54:15,059 - mmdet - INFO - Exp name: centernet_resnet18_140e_coco.py\n",
      "2022-06-02 08:54:15,059 - mmdet - INFO - Epoch(val) [1][6]\tbbox_mAP: 0.0000, bbox_mAP_50: 0.0000, bbox_mAP_75: 0.0000, bbox_mAP_s: -1.0000, bbox_mAP_m: -1.0000, bbox_mAP_l: 0.0000, bbox_mAP_copypaste: 0.000 0.000 0.000 -1.000 -1.000 0.000\n",
      "2022-06-02 08:54:17,710 - mmdet - INFO - Epoch [2][8/16]\tlr: 4.795e-04, eta: 0:00:06, time: 0.331, data_time: 0.266, memory: 478, loss_center_heatmap: 4.1870, loss_wh: 7.3511, loss_offset: 0.4856, loss: 12.0237, grad_norm: 64.4560\n",
      "2022-06-02 08:54:18,085 - mmdet - INFO - Exp name: centernet_resnet18_140e_coco.py\n",
      "2022-06-02 08:54:18,085 - mmdet - INFO - Epoch [2][16/16]\tlr: 6.394e-04, eta: 0:00:03, time: 0.047, data_time: 0.004, memory: 478, loss_center_heatmap: 4.8829, loss_wh: 7.3826, loss_offset: 0.4579, loss: 12.7234, grad_norm: 71.8576\n",
      "2022-06-02 08:54:18,105 - mmdet - INFO - Saving checkpoint at 2 epochs\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 6/6, 43.4 task/s, elapsed: 0s, ETA:     0s2022-06-02 08:54:18,438 - mmdet - INFO - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.02s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      "2022-06-02 08:54:18,469 - mmdet - INFO - \n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.000\n",
      "\n",
      "2022-06-02 08:54:18,470 - mmdet - INFO - Exp name: centernet_resnet18_140e_coco.py\n",
      "2022-06-02 08:54:18,470 - mmdet - INFO - Epoch(val) [2][6]\tbbox_mAP: 0.0000, bbox_mAP_50: 0.0000, bbox_mAP_75: 0.0000, bbox_mAP_s: -1.0000, bbox_mAP_m: -1.0000, bbox_mAP_l: 0.0000, bbox_mAP_copypaste: 0.000 0.000 0.000 -1.000 -1.000 0.000\n",
      "2022-06-02 08:54:21,147 - mmdet - INFO - Epoch [3][8/16]\tlr: 7.992e-04, eta: 0:00:01, time: 0.334, data_time: 0.264, memory: 478, loss_center_heatmap: 4.6758, loss_wh: 7.1055, loss_offset: 0.5193, loss: 12.3007, grad_norm: 57.0786\n",
      "2022-06-02 08:54:21,550 - mmdet - INFO - Exp name: centernet_resnet18_140e_coco.py\n",
      "2022-06-02 08:54:21,550 - mmdet - INFO - Epoch [3][16/16]\tlr: 9.591e-04, eta: 0:00:00, time: 0.050, data_time: 0.004, memory: 478, loss_center_heatmap: 3.7863, loss_wh: 7.0853, loss_offset: 0.4573, loss: 11.3289, grad_norm: 37.3446\n",
      "2022-06-02 08:54:21,575 - mmdet - INFO - Saving checkpoint at 3 epochs\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 6/6, 32.8 task/s, elapsed: 0s, ETA:     0s2022-06-02 08:54:21,985 - mmdet - INFO - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.02s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      "2022-06-02 08:54:22,017 - mmdet - INFO - \n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.000\n",
      "\n",
      "2022-06-02 08:54:22,018 - mmdet - INFO - Exp name: centernet_resnet18_140e_coco.py\n",
      "2022-06-02 08:54:22,018 - mmdet - INFO - Epoch(val) [3][6]\tbbox_mAP: 0.0000, bbox_mAP_50: 0.0000, bbox_mAP_75: 0.0000, bbox_mAP_s: -1.0000, bbox_mAP_m: -1.0000, bbox_mAP_l: 0.0000, bbox_mAP_copypaste: 0.000 0.000 0.000 -1.000 -1.000 0.000\n"
     ]
    }
   ],
   "source": [
    "MMDET_HOME = \"/opt/src/mmdetection\"\n",
    "CONFIG_FILE = f\"{MMDET_HOME}/configs/centernet/centernet_resnet18_140e_coco.py\"\n",
    "EXPERIMENT_PATH = \"/workspace/tmp/runs/coco2017_cat_dog_centernet_resnet18\"\n",
    "DATA_ROOT = \"/workspace/coco2017_cat_dog\"\n",
    "NUM_CLASSES = \"2\"\n",
    "CLASSES = \"cat,dog\"\n",
    "\n",
    "ARGS = [f\"{CONFIG_FILE}\",\n",
    "        f\"--work-dir {EXPERIMENT_PATH}\",\n",
    "        f\"--seed 41\",\n",
    "        f\"--launcher none\",\n",
    "        f\"--cfg-options\",\n",
    "        f\"'model.bbox_head.num_classes={NUM_CLASSES}'\",\n",
    "        f\"'data.samples_per_gpu=2'\",\n",
    "        f\"'data.workers_per_gpu=2'\",\n",
    "        f\"'data.train.dataset.classes={CLASSES}'\",\n",
    "        f\"'data.train.dataset.ann_file={DATA_ROOT}/train/labels.json'\",\n",
    "        f\"'data.train.dataset.img_prefix={DATA_ROOT}/train/data/'\",\n",
    "        f\"'data.val.classes={CLASSES}'\",\n",
    "        f\"'data.val.ann_file={DATA_ROOT}/validation/labels.json'\",\n",
    "        f\"'data.val.img_prefix={DATA_ROOT}/validation/data/'\",\n",
    "        f\"'data.test.classes={CLASSES}'\",\n",
    "        f\"'data.test.ann_file={DATA_ROOT}/validation/labels.json'\",\n",
    "        f\"'data.test.img_prefix={DATA_ROOT}/validation/data/'\",\n",
    "        \"'log_config.interval=8'\",  # 50, 100 or 200\n",
    "        \"'runner.max_epochs=3'\"]  # 12, 24 or 30\n",
    "ARGS = \" \".join(ARGS)\n",
    "print(f\"{ARGS=}\")\n",
    "\n",
    "!cd {MMDET_HOME} && python tools/train.py {ARGS}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77e0101",
   "metadata": {},
   "source": [
    "### Training on multiple GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "854bc35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARGS=\"/opt/src/mmdetection/configs/centernet/centernet_resnet18_140e_coco.py --work-dir /workspace/tmp/runs/coco2017_cat_dog_centernet_resnet18 --seed 41 --launcher pytorch --cfg-options 'model.bbox_head.num_classes=2' 'data.samples_per_gpu=2' 'data.workers_per_gpu=2' 'data.train.dataset.classes=cat,dog' 'data.train.dataset.ann_file=/workspace/coco2017_cat_dog/train/labels.json' 'data.train.dataset.img_prefix=/workspace/coco2017_cat_dog/train/data/' 'data.val.classes=cat,dog' 'data.val.ann_file=/workspace/coco2017_cat_dog/validation/labels.json' 'data.val.img_prefix=/workspace/coco2017_cat_dog/validation/data/' 'data.test.classes=cat,dog' 'data.test.ann_file=/workspace/coco2017_cat_dog/validation/labels.json' 'data.test.img_prefix=/workspace/coco2017_cat_dog/validation/data/' 'log_config.interval=8' 'runner.max_epochs=3'\"\n",
      "/opt/src/mmdetection/mmdet/utils/setup_env.py:38: UserWarning: Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\n",
      "  warnings.warn(\n",
      "/opt/src/mmdetection/mmdet/utils/setup_env.py:48: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\n",
      "  warnings.warn(\n",
      "2022-06-02 08:54:26,736 - mmdet - INFO - Environment info:\n",
      "------------------------------------------------------------\n",
      "sys.platform: linux\n",
      "Python: 3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]\n",
      "CUDA available: True\n",
      "GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU\n",
      "CUDA_HOME: /usr/local/cuda\n",
      "NVCC: Cuda compilation tools, release 11.3, V11.3.109\n",
      "GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
      "PyTorch: 1.11.0\n",
      "PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.3\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 8.2\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "TorchVision: 0.12.0\n",
      "OpenCV: 4.5.5\n",
      "MMCV: 1.5.2\n",
      "MMCV Compiler: GCC 7.3\n",
      "MMCV CUDA Compiler: 11.3\n",
      "MMDetection: 2.24.1+73b4e65\n",
      "------------------------------------------------------------\n",
      "\n",
      "2022-06-02 08:54:27,049 - mmdet - INFO - Distributed training: True\n",
      "2022-06-02 08:54:27,344 - mmdet - INFO - Config:\n",
      "dataset_type = 'CocoDataset'\n",
      "data_root = 'data/coco/'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile', to_float32=True, color_type='color'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        type='PhotoMetricDistortion',\n",
      "        brightness_delta=32,\n",
      "        contrast_range=(0.5, 1.5),\n",
      "        saturation_range=(0.5, 1.5),\n",
      "        hue_delta=18),\n",
      "    dict(\n",
      "        type='RandomCenterCropPad',\n",
      "        crop_size=(512, 512),\n",
      "        ratios=(0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3),\n",
      "        mean=[0, 0, 0],\n",
      "        std=[1, 1, 1],\n",
      "        to_rgb=True,\n",
      "        test_pad_mode=None),\n",
      "    dict(type='Resize', img_scale=(512, 512), keep_ratio=True),\n",
      "    dict(type='RandomFlip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile', to_float32=True),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        scale_factor=1.0,\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(\n",
      "                type='RandomCenterCropPad',\n",
      "                ratios=None,\n",
      "                border=None,\n",
      "                mean=[0, 0, 0],\n",
      "                std=[1, 1, 1],\n",
      "                to_rgb=True,\n",
      "                test_mode=True,\n",
      "                test_pad_mode=['logical_or', 31],\n",
      "                test_pad_add_pix=1),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(\n",
      "                type='Collect',\n",
      "                meta_keys=('filename', 'ori_filename', 'ori_shape',\n",
      "                           'img_shape', 'pad_shape', 'scale_factor', 'flip',\n",
      "                           'flip_direction', 'img_norm_cfg', 'border'),\n",
      "                keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=2,\n",
      "    workers_per_gpu=2,\n",
      "    train=dict(\n",
      "        type='RepeatDataset',\n",
      "        times=5,\n",
      "        dataset=dict(\n",
      "            type='CocoDataset',\n",
      "            ann_file='/workspace/coco2017_cat_dog/train/labels.json',\n",
      "            img_prefix='/workspace/coco2017_cat_dog/train/data/',\n",
      "            pipeline=[\n",
      "                dict(\n",
      "                    type='LoadImageFromFile',\n",
      "                    to_float32=True,\n",
      "                    color_type='color'),\n",
      "                dict(type='LoadAnnotations', with_bbox=True),\n",
      "                dict(\n",
      "                    type='PhotoMetricDistortion',\n",
      "                    brightness_delta=32,\n",
      "                    contrast_range=(0.5, 1.5),\n",
      "                    saturation_range=(0.5, 1.5),\n",
      "                    hue_delta=18),\n",
      "                dict(\n",
      "                    type='RandomCenterCropPad',\n",
      "                    crop_size=(512, 512),\n",
      "                    ratios=(0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3),\n",
      "                    mean=[0, 0, 0],\n",
      "                    std=[1, 1, 1],\n",
      "                    to_rgb=True,\n",
      "                    test_pad_mode=None),\n",
      "                dict(type='Resize', img_scale=(512, 512), keep_ratio=True),\n",
      "                dict(type='RandomFlip', flip_ratio=0.5),\n",
      "                dict(\n",
      "                    type='Normalize',\n",
      "                    mean=[123.675, 116.28, 103.53],\n",
      "                    std=[58.395, 57.12, 57.375],\n",
      "                    to_rgb=True),\n",
      "                dict(type='DefaultFormatBundle'),\n",
      "                dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "            ],\n",
      "            classes=['cat', 'dog'])),\n",
      "    val=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='/workspace/coco2017_cat_dog/validation/labels.json',\n",
      "        img_prefix='/workspace/coco2017_cat_dog/validation/data/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile', to_float32=True),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                scale_factor=1.0,\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(\n",
      "                        type='RandomCenterCropPad',\n",
      "                        ratios=None,\n",
      "                        border=None,\n",
      "                        mean=[0, 0, 0],\n",
      "                        std=[1, 1, 1],\n",
      "                        to_rgb=True,\n",
      "                        test_mode=True,\n",
      "                        test_pad_mode=['logical_or', 31],\n",
      "                        test_pad_add_pix=1),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='DefaultFormatBundle'),\n",
      "                    dict(\n",
      "                        type='Collect',\n",
      "                        meta_keys=('filename', 'ori_filename', 'ori_shape',\n",
      "                                   'img_shape', 'pad_shape', 'scale_factor',\n",
      "                                   'flip', 'flip_direction', 'img_norm_cfg',\n",
      "                                   'border'),\n",
      "                        keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        classes=['cat', 'dog']),\n",
      "    test=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='/workspace/coco2017_cat_dog/validation/labels.json',\n",
      "        img_prefix='/workspace/coco2017_cat_dog/validation/data/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile', to_float32=True),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                scale_factor=1.0,\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(\n",
      "                        type='RandomCenterCropPad',\n",
      "                        ratios=None,\n",
      "                        border=None,\n",
      "                        mean=[0, 0, 0],\n",
      "                        std=[1, 1, 1],\n",
      "                        to_rgb=True,\n",
      "                        test_mode=True,\n",
      "                        test_pad_mode=['logical_or', 31],\n",
      "                        test_pad_add_pix=1),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='DefaultFormatBundle'),\n",
      "                    dict(\n",
      "                        type='Collect',\n",
      "                        meta_keys=('filename', 'ori_filename', 'ori_shape',\n",
      "                                   'img_shape', 'pad_shape', 'scale_factor',\n",
      "                                   'flip', 'flip_direction', 'img_norm_cfg',\n",
      "                                   'border'),\n",
      "                        keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        classes=['cat', 'dog']))\n",
      "evaluation = dict(interval=1, metric='bbox')\n",
      "optimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=1000,\n",
      "    warmup_ratio=0.001,\n",
      "    step=[18, 24])\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=3)\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=8, hooks=[dict(type='TextLoggerHook')])\n",
      "custom_hooks = [dict(type='NumClassCheckHook')]\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "opencv_num_threads = 0\n",
      "mp_start_method = 'fork'\n",
      "auto_scale_lr = dict(enable=False, base_batch_size=128)\n",
      "model = dict(\n",
      "    type='CenterNet',\n",
      "    backbone=dict(\n",
      "        type='ResNet',\n",
      "        depth=18,\n",
      "        norm_eval=False,\n",
      "        norm_cfg=dict(type='BN'),\n",
      "        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet18')),\n",
      "    neck=dict(\n",
      "        type='CTResNetNeck',\n",
      "        in_channel=512,\n",
      "        num_deconv_filters=(256, 128, 64),\n",
      "        num_deconv_kernels=(4, 4, 4),\n",
      "        use_dcn=False),\n",
      "    bbox_head=dict(\n",
      "        type='CenterNetHead',\n",
      "        num_classes=2,\n",
      "        in_channel=64,\n",
      "        feat_channel=64,\n",
      "        loss_center_heatmap=dict(type='GaussianFocalLoss', loss_weight=1.0),\n",
      "        loss_wh=dict(type='L1Loss', loss_weight=0.1),\n",
      "        loss_offset=dict(type='L1Loss', loss_weight=1.0)),\n",
      "    train_cfg=None,\n",
      "    test_cfg=dict(topk=100, local_maximum_kernel=3, max_per_img=100))\n",
      "work_dir = '/workspace/tmp/runs/coco2017_cat_dog_centernet_resnet18'\n",
      "auto_resume = False\n",
      "gpu_ids = range(0, 1)\n",
      "\n",
      "2022-06-02 08:54:27,345 - mmdet - INFO - Set random seed to 41, deterministic: False\n",
      "2022-06-02 08:54:27,439 - mmdet - INFO - initialize ResNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'torchvision://resnet18'}\n",
      "2022-06-02 08:54:27,440 - mmcv - INFO - load model from: torchvision://resnet18\n",
      "2022-06-02 08:54:27,440 - mmcv - INFO - load checkpoint from torchvision path: torchvision://resnet18\n",
      "2022-06-02 08:54:27,473 - mmcv - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: fc.weight, fc.bias\n",
      "\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "2022-06-02 08:54:30,083 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "2022-06-02 08:54:30,086 - mmdet - INFO - Start running, host: root@48fe24f1f65c, work_dir: /workspace/tmp/runs/coco2017_cat_dog_centernet_resnet18\n",
      "2022-06-02 08:54:30,087 - mmdet - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) DistEvalHook                       \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) DistEvalHook                       \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) DistEvalHook                       \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) DistEvalHook                       \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) DistEvalHook                       \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2022-06-02 08:54:30,087 - mmdet - INFO - workflow: [('train', 1)], max: 3 epochs\n",
      "2022-06-02 08:54:30,087 - mmdet - INFO - Checkpoints will be saved to /workspace/tmp/runs/coco2017_cat_dog_centernet_resnet18 by HardDiskBackend.\n",
      "2022-06-02 08:54:33,195 - mmcv - INFO - Reducer buckets have been rebuilt in this iteration.\n",
      "2022-06-02 08:54:33,577 - mmdet - INFO - Epoch [1][8/16]\tlr: 1.599e-04, eta: 0:00:17, time: 0.436, data_time: 0.268, memory: 533, loss_center_heatmap: 27.0698, loss_wh: 6.9741, loss_offset: 0.5295, loss: 34.5733, grad_norm: 180.3619\n",
      "2022-06-02 08:54:34,010 - mmdet - INFO - Exp name: centernet_resnet18_140e_coco.py\n",
      "2022-06-02 08:54:34,010 - mmdet - INFO - Epoch [1][16/16]\tlr: 3.197e-04, eta: 0:00:07, time: 0.054, data_time: 0.004, memory: 533, loss_center_heatmap: 11.3412, loss_wh: 8.1509, loss_offset: 0.4252, loss: 19.9173, grad_norm: 75.9069\n",
      "2022-06-02 08:54:34,031 - mmdet - INFO - Saving checkpoint at 1 epochs\n",
      "[                                                  ] 0/6, elapsed: 0s, ETA:/opt/src/mmdetection/mmdet/models/utils/gaussian_target.py:227: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  topk_clses = topk_inds // (height * width)\n",
      "/opt/src/mmdetection/mmdet/models/utils/gaussian_target.py:229: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  topk_ys = topk_inds // width\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 6/6, 2.7 task/s, elapsed: 2s, ETA:     0s\n",
      "\n",
      "2022-06-02 08:54:36,479 - mmdet - INFO - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.02s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      "2022-06-02 08:54:36,511 - mmdet - INFO - \n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.000\n",
      "\n",
      "2022-06-02 08:54:36,512 - mmdet - INFO - Exp name: centernet_resnet18_140e_coco.py\n",
      "2022-06-02 08:54:36,512 - mmdet - INFO - Epoch(val) [1][6]\tbbox_mAP: 0.0000, bbox_mAP_50: 0.0000, bbox_mAP_75: 0.0000, bbox_mAP_s: -1.0000, bbox_mAP_m: -1.0000, bbox_mAP_l: 0.0000, bbox_mAP_copypaste: 0.000 0.000 0.000 -1.000 -1.000 0.000\n",
      "2022-06-02 08:54:39,205 - mmdet - INFO - Epoch [2][8/16]\tlr: 4.795e-04, eta: 0:00:06, time: 0.336, data_time: 0.264, memory: 533, loss_center_heatmap: 4.2041, loss_wh: 7.0225, loss_offset: 0.4489, loss: 11.6755, grad_norm: 62.6691\n",
      "2022-06-02 08:54:39,586 - mmdet - INFO - Exp name: centernet_resnet18_140e_coco.py\n",
      "2022-06-02 08:54:39,586 - mmdet - INFO - Epoch [2][16/16]\tlr: 6.394e-04, eta: 0:00:03, time: 0.048, data_time: 0.004, memory: 533, loss_center_heatmap: 4.9559, loss_wh: 6.9032, loss_offset: 0.3860, loss: 12.2451, grad_norm: 73.5289\n",
      "2022-06-02 08:54:39,608 - mmdet - INFO - Saving checkpoint at 2 epochs\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 6/6, 2.7 task/s, elapsed: 2s, ETA:     0s\n",
      "\n",
      "2022-06-02 08:54:42,056 - mmdet - INFO - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.02s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      "2022-06-02 08:54:42,088 - mmdet - INFO - \n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.000\n",
      "\n",
      "2022-06-02 08:54:42,088 - mmdet - INFO - Exp name: centernet_resnet18_140e_coco.py\n",
      "2022-06-02 08:54:42,088 - mmdet - INFO - Epoch(val) [2][6]\tbbox_mAP: 0.0000, bbox_mAP_50: 0.0000, bbox_mAP_75: 0.0000, bbox_mAP_s: -1.0000, bbox_mAP_m: -1.0000, bbox_mAP_l: 0.0000, bbox_mAP_copypaste: 0.000 0.000 0.000 -1.000 -1.000 0.000\n",
      "2022-06-02 08:54:44,794 - mmdet - INFO - Epoch [3][8/16]\tlr: 7.992e-04, eta: 0:00:01, time: 0.338, data_time: 0.265, memory: 533, loss_center_heatmap: 4.7021, loss_wh: 7.3319, loss_offset: 0.4846, loss: 12.5186, grad_norm: 60.0138\n",
      "2022-06-02 08:54:45,162 - mmdet - INFO - Exp name: centernet_resnet18_140e_coco.py\n",
      "2022-06-02 08:54:45,162 - mmdet - INFO - Epoch [3][16/16]\tlr: 9.591e-04, eta: 0:00:00, time: 0.046, data_time: 0.004, memory: 533, loss_center_heatmap: 3.8721, loss_wh: 7.9769, loss_offset: 0.4412, loss: 12.2902, grad_norm: 39.8002\n",
      "2022-06-02 08:54:45,184 - mmdet - INFO - Saving checkpoint at 3 epochs\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 6/6, 2.7 task/s, elapsed: 2s, ETA:     0s\n",
      "\n",
      "2022-06-02 08:54:47,606 - mmdet - INFO - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.02s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      "2022-06-02 08:54:47,640 - mmdet - INFO - \n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.000\n",
      "\n",
      "2022-06-02 08:54:47,640 - mmdet - INFO - Exp name: centernet_resnet18_140e_coco.py\n",
      "2022-06-02 08:54:47,640 - mmdet - INFO - Epoch(val) [3][6]\tbbox_mAP: 0.0000, bbox_mAP_50: 0.0000, bbox_mAP_75: 0.0000, bbox_mAP_s: -1.0000, bbox_mAP_m: -1.0000, bbox_mAP_l: 0.0000, bbox_mAP_copypaste: 0.000 0.000 0.000 -1.000 -1.000 0.000\n"
     ]
    }
   ],
   "source": [
    "CFG_NUM_GPUS = 1\n",
    "MMDET_HOME = \"/opt/src/mmdetection\"\n",
    "CONFIG_FILE = f\"{MMDET_HOME}/configs/centernet/centernet_resnet18_140e_coco.py\"\n",
    "EXPERIMENT_PATH = \"/workspace/tmp/runs/coco2017_cat_dog_centernet_resnet18\"\n",
    "DATA_ROOT = \"/workspace/coco2017_cat_dog\"\n",
    "NUM_CLASSES = \"2\"\n",
    "CLASSES = \"cat,dog\"\n",
    "\n",
    "ARGS = [f\"{CONFIG_FILE}\",\n",
    "        f\"--work-dir {EXPERIMENT_PATH}\",\n",
    "        f\"--seed 41\",\n",
    "        f\"--launcher pytorch\",  # for distributed\n",
    "        f\"--cfg-options\",\n",
    "        f\"'model.bbox_head.num_classes={NUM_CLASSES}'\",\n",
    "        f\"'data.samples_per_gpu=2'\",\n",
    "        f\"'data.workers_per_gpu=2'\",\n",
    "        f\"'data.train.dataset.classes={CLASSES}'\",\n",
    "        f\"'data.train.dataset.ann_file={DATA_ROOT}/train/labels.json'\",\n",
    "        f\"'data.train.dataset.img_prefix={DATA_ROOT}/train/data/'\",\n",
    "        f\"'data.val.classes={CLASSES}'\",\n",
    "        f\"'data.val.ann_file={DATA_ROOT}/validation/labels.json'\",\n",
    "        f\"'data.val.img_prefix={DATA_ROOT}/validation/data/'\",\n",
    "        f\"'data.test.classes={CLASSES}'\",\n",
    "        f\"'data.test.ann_file={DATA_ROOT}/validation/labels.json'\",\n",
    "        f\"'data.test.img_prefix={DATA_ROOT}/validation/data/'\",\n",
    "        \"'log_config.interval=8'\",  # 50, 100 or 200\n",
    "        \"'runner.max_epochs=3'\"]  # 12, 24 or 30\n",
    "ARGS = \" \".join(ARGS)\n",
    "print(f\"{ARGS=}\")\n",
    "\n",
    "!cd {MMDET_HOME} && python -m torch.distributed.run --nproc_per_node {CFG_NUM_GPUS} tools/train.py {ARGS}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
